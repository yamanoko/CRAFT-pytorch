{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yukinori/miniconda3/envs/pytorch_bootcamp/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/yukinori/miniconda3/envs/pytorch_bootcamp/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from checkpoint (craft_mlt_25k.pth)\n",
      "elapsed time : 214.97649574279785s/Desktop/segmentation_model/self_supervised_cropped/Nobleza_virtuosa_53_left.jpggg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('python test.py --trained_model=\"craft_mlt_25k.pth\" --test_folder=\"/home/yukinori/Desktop/segmentation_model/self_supervised_cropped\" --text_threshold=0.8 --result_folder=\"txt_result/\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def save_cropped_images(image_dir, txt_dir, output_dir):\n",
    "\tif not os.path.exists(output_dir):\n",
    "\t\tos.makedirs(output_dir)\n",
    "\ttxt_list = os.listdir(txt_dir)\n",
    "\tfor txt_file in txt_list:\n",
    "\t\timg = cv2.imread(os.path.join(image_dir, txt_file.replace(\".txt\", \".jpg\")))\n",
    "\t\twith open(os.path.join(txt_dir, txt_file), \"r\") as f:\n",
    "\t\t\tlines = f.readlines()\n",
    "\t\t\tfor i, line in enumerate(lines):\n",
    "\t\t\t\tprocessed_line = line.strip('\\n')\n",
    "\t\t\t\tprocessed_line = processed_line.split(',')\n",
    "\t\t\t\tpts = np.array(processed_line, np.float32)\n",
    "\t\t\t\tpts = pts.reshape((-1, 2))\n",
    "\t\t\t\twidth = int(max(np.linalg.norm(pts[1] - pts[0]), np.linalg.norm(pts[3] - pts[2])))\n",
    "\t\t\t\theight = int(max(np.linalg.norm(pts[2] - pts[1]), np.linalg.norm(pts[3] - pts[0])))\n",
    "\t\t\t\tdst = np.array([\n",
    "\t\t\t\t\t[0, 0],\n",
    "\t\t\t\t\t[width - 1, 0],\n",
    "\t\t\t\t\t[width - 1, height - 1],\n",
    "\t\t\t\t\t[0, height - 1]\n",
    "\t\t\t\t], dtype=\"float32\")\n",
    "\t\t\t\tM = cv2.getPerspectiveTransform(pts, dst)\n",
    "\t\t\t\twarped = cv2.warpPerspective(img, M, (width, height))\n",
    "\t\t\t\tcv2.imwrite(os.path.join(output_dir, f\"{i}_{txt_file.replace('.txt', '.jpg')}\"), warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def save_line_bbox(img_dir, txt_dir, output_dir, threshold=20):\n",
    "    assert output_dir != txt_dir\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    txt_list = os.listdir(txt_dir)\n",
    "    for txt_file in txt_list:\n",
    "        img = cv2.imread(os.path.join(img_dir, txt_file.replace(\".txt\", \".jpg\")))\n",
    "        height, width = img.shape[:2]\n",
    "        with open(os.path.join(txt_dir, txt_file), \"r\") as f:\n",
    "            reader = csv.reader(f)\n",
    "            bboxes = list(reader)\n",
    "            centers = [(int(bbox[1]) + int(bbox[5])) // 2 for bbox in bboxes]\n",
    "            bboxes = [x for _, x in sorted(zip(centers, bboxes))]\n",
    "            if bboxes == []:\n",
    "                continue\n",
    "            lines = []\n",
    "            line = [bboxes[0]]\n",
    "            line_first_center = 0\n",
    "            for i in range(1, len(bboxes)):\n",
    "                if abs(centers[i] - centers[line_first_center]) < threshold:\n",
    "                    line.append(bboxes[i])\n",
    "                else:\n",
    "                    line_first_center = i\n",
    "                    lines.append(line)\n",
    "                    line = [bboxes[i]]\n",
    "            lines.append(line)\n",
    "        for i, line in enumerate(lines):\n",
    "            # min_x = min_y = int('inf')\n",
    "            min_x = width\n",
    "            min_y = height\n",
    "            max_x = max_y = 0\n",
    "            for bbox in line:\n",
    "                min_x = min(min_x, int(bbox[0]), int(bbox[6]))\n",
    "                min_y = min(min_y, int(bbox[1]), int(bbox[3]))\n",
    "                max_x = max(max_x, int(bbox[2]), int(bbox[4]))\n",
    "                max_y = max(max_y, int(bbox[5]), int(bbox[7]))\n",
    "            with open(os.path.join(output_dir, f\"{txt_file}\"), \"a\") as f:\n",
    "                f.write(f\"{min_x},{min_y},{max_x},{min_y},{max_x},{max_y},{min_x},{max_y}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_line_bbox(\"/home/yukinori/Desktop/segmentation_model/self_supervised_cropped\", \"txt_result\", \"line_txt_result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cropped_images(\"/home/yukinori/Desktop/segmentation_model/self_supervised_cropped_colored\", \"line_txt_result\", \"cropped_images_line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "test_img = cv2.imread(\"cropped_images_v2/183_Noble_perfecto_5_left.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 119, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
